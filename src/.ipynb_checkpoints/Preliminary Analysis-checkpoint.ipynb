{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MTurk ID', 'Sentence Number', 'List Number', 'Subset Number', 'Trial Number', 'Target Sentence', 'Scrambled Sentence', 'Produced Sentence', 'Time (ms)', 'Time', 'Bugged']\n"
     ]
    }
   ],
   "source": [
    "# basic data processing and cleaning\n",
    "# note: we manually changed the header line of the csv,\n",
    "# removing the spaces between commas and modifying the last column name\n",
    "\n",
    "trials = pd.read_csv(\"../data/processed_data.csv\")\n",
    "#print(df[:10])\n",
    "print(list(trials.columns.values))\n",
    "#print(np.size(trials)) # 327250\n",
    "\n",
    "# get rid of bugged data, which amounts to 9416 records\n",
    "trials = trials[trials['Bugged'] != \"Bugged\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add column for whether produced matches target\n",
    "def ProdMatchesTgt(dataframe_row):\n",
    "    if dataframe_row['Target Sentence'] == dataframe_row['Produced Sentence']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "trials['ProdMatchesOrig'] = trials.apply(ProdMatchesTgt, axis=1)    \n",
    "#print(trials[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add column for longest matching substring\n",
    "# https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Longest_common_substring#Python_3\n",
    "# https://en.wikipedia.org/wiki/Longest_common_substring_problem\n",
    "\n",
    "#def longestMatchingSubstring( dataframe_row ):\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         MTurk ID  Sentence Number  List Number  Subset Number  Trial Number  \\\n",
      "1  A30RAYNDOWQ61S               56            3              2             2   \n",
      "2  A30RAYNDOWQ61S               51            3              2             3   \n",
      "3  A30RAYNDOWQ61S               91            3              2             4   \n",
      "4  A30RAYNDOWQ61S               58            3              2             5   \n",
      "5  A30RAYNDOWQ61S               83            3              2             6   \n",
      "\n",
      "                                     Target Sentence  \\\n",
      "1  the blast shattered the windows of the villa a...   \n",
      "2  the equipment was often moved quickly when ins...   \n",
      "3  evidence from abroad showed students were prep...   \n",
      "4  south africa has openly expressed willingness ...   \n",
      "5  the regular bus service had been suspended bec...   \n",
      "\n",
      "                                  Scrambled Sentence  \\\n",
      "1  neighbouring windows shattered the other the h...   \n",
      "2  the to quickly equipment inspectors moved were...   \n",
      "3  showed students large to were out loans eviden...   \n",
      "4  with openly africa establish china to has sout...   \n",
      "5  been suspended bus because fuel the the servic...   \n",
      "\n",
      "                                   Produced Sentence  Time (ms)          Time  \\\n",
      "1  the blast shattered the windows of the villa a...     117637  1 min 57 sec   \n",
      "2  equipment was often quickly moved when the ins...     513810  8 min 33 sec   \n",
      "3  evidence showed students from abroad were prep...      78273  1 min 18 sec   \n",
      "4  south africa has expressed willingness to open...      85852  1 min 25 sec   \n",
      "5  the regular bus service had been suspended bec...      75546  1 min 15 sec   \n",
      "\n",
      "  Bugged ProdMatchesOrig  proportionMatchingBigram  \n",
      "1   Safe            True                  1.000000  \n",
      "2   Safe           False                  0.545455  \n",
      "3   Safe           False                  0.727273  \n",
      "4   Safe           False                  0.727273  \n",
      "5   Safe            True                  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# proportion that match original\n",
    "# For each of 30,000 trials, identify the proportion of word pairs that match the original sentence \n",
    "# in order (we'll have to figure out what to do with duplicates, which are common. esp. for function \n",
    "# words; perhaps we should restrict things to content words for starters).\n",
    "\n",
    "# I'm going to interpret this as: how many bigrams from the target appeared in the production\n",
    "# divided by the total number of bigrams in the target\n",
    "\n",
    "# bypassing efficiency for now\n",
    "def getBigrams( string ):\n",
    "    bigs = []\n",
    "    sep = string.lower().split()\n",
    "    for k,v in enumerate(sep):\n",
    "        if k == len(sep) - 1:\n",
    "            break\n",
    "        else:\n",
    "            bigs.append((v,sep[k+1]))\n",
    "    return bigs\n",
    "\n",
    "def searchForBigrams( bigrams_prod, bigrams_tgt ):\n",
    "    ''' bigrams is a list of tuples of word pairs, returns number of bigrams from tgt in prod\n",
    "        divided by total number in prod \n",
    "    '''\n",
    "    # set intersection\n",
    "    bigList = [bigrams_prod,bigrams_tgt]\n",
    "    bigList = [set(a) for a in bigList]\n",
    "    \n",
    "    numProdBig = len(bigList[1])\n",
    "    intersectionTgtBig = set.intersection(*bigList)\n",
    "\n",
    "    return len( intersectionTgtBig ) / numProdBig\n",
    "\n",
    "# test\n",
    "#b1 = getBigrams(\"this is a sample sentence\")\n",
    "#b2 = getBigrams(\"this is a very cool sample sentence\")\n",
    "#print( searchForBigrams( b1,b2))  # works out all right!\n",
    "    \n",
    "def bigramDriver(dataframe_row):\n",
    "    b1 = getBigrams(dataframe_row['Produced Sentence'])\n",
    "    b2 = getBigrams(dataframe_row['Target Sentence'])\n",
    "    \n",
    "    proportion = searchForBigrams(b1,b2)\n",
    "    return proportion\n",
    "\n",
    "trials['proportionMatchingBigram'] = trials.apply(bigramDriver, axis=1)\n",
    "\n",
    "print(trials[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# edit distance between production and original\n",
    "# https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance#Python\n",
    "\n",
    "# this might actually need to be optimized\n",
    "def levenshtein(s, t):\n",
    "        ''' From Wikipedia article; Iterative with two matrix rows. '''\n",
    "        if s == t: return 0\n",
    "        elif len(s) == 0: return len(t)\n",
    "        elif len(t) == 0: return len(s)\n",
    "        v0 = [None] * (len(t) + 1)\n",
    "        v1 = [None] * (len(t) + 1)\n",
    "        for i in range(len(v0)):\n",
    "            v0[i] = i\n",
    "        for i in range(len(s)):\n",
    "            v1[0] = i + 1\n",
    "            for j in range(len(t)):\n",
    "                cost = 0 if s[i] == t[j] else 1\n",
    "                v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)\n",
    "            for j in range(len(v0)):\n",
    "                v0[j] = v1[j]\n",
    "                \n",
    "        return v1[len(t)]\n",
    "\n",
    "    \n",
    "def editDriver( dataframe_row ):\n",
    "    a = dataframe_row['Produced Sentence']\n",
    "    b = dataframe_row['Target Sentence']\n",
    "    \n",
    "    return levenshtein( a, b )\n",
    "\n",
    "s = \"the equipment was often moved quickly when inspectors were about to arrive\"\n",
    "t = \"equipment was often quickly moved when the inspectors were about to arrive\"\n",
    "print(levenshtein(s,t))\n",
    "\n",
    "#trials['editDist'] = trials.apply(editDriver, axis=1)\n",
    "\n",
    "#print(trials[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
