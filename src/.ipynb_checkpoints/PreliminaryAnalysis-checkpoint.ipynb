{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MTurk ID', 'Sentence Number', 'List Number', 'Subset Number', 'Trial Number', 'Target Sentence', 'Scrambled Sentence', 'Produced Sentence', 'Time (ms)', 'Time', 'Bugged']\n"
     ]
    }
   ],
   "source": [
    "# basic data processing and cleaning\n",
    "# note: we manually changed the header line of the csv,\n",
    "# removing the spaces between commas and modifying the last column name\n",
    "\n",
    "trials = pd.read_csv(\"../data/processed_data.csv\")\n",
    "#print(df[:10])\n",
    "print(list(trials.columns.values))\n",
    "#print(np.size(trials)) # 327250\n",
    "\n",
    "# get rid of bugged data, which amounts to 9416 records\n",
    "trials = trials[trials['Bugged'] != \"Bugged\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add column for whether produced matches target\n",
    "def ProdMatchesTgt(dataframe_row):\n",
    "    if dataframe_row['Target Sentence'] == dataframe_row['Produced Sentence']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "trials['ProdMatchesOrig'] = trials.apply(ProdMatchesTgt, axis=1)    \n",
    "#print(trials[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"trials['proportionMatchingBigram'] = trials.apply(bigramDriver, axis=1)\\n\\nprint(trials[:5])\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion that match original\n",
    "# For each of 30,000 trials, identify the proportion of word pairs that match the original sentence \n",
    "# in order (we'll have to figure out what to do with duplicates, which are common. esp. for function \n",
    "# words; perhaps we should restrict things to content words for starters).\n",
    "\n",
    "# I'm going to interpret this as: how many bigrams from the target appeared in the production\n",
    "# divided by the total number of bigrams in the target\n",
    "\n",
    "# bypassing efficiency for now\n",
    "def getBigrams( string ):\n",
    "    bigs = []\n",
    "    sep = string.lower().split()\n",
    "    for k,v in enumerate(sep):\n",
    "        if k == len(sep) - 1:\n",
    "            break\n",
    "        else:\n",
    "            bigs.append((v,sep[k+1]))\n",
    "    return bigs\n",
    "\n",
    "def searchForBigrams( bigrams_prod, bigrams_tgt ):\n",
    "    ''' bigrams is a list of tuples of word pairs, returns number of bigrams from tgt in prod\n",
    "        divided by total number in prod \n",
    "    '''\n",
    "    # set intersection\n",
    "    bigList = [bigrams_prod,bigrams_tgt]\n",
    "    bigList = [set(a) for a in bigList]\n",
    "    \n",
    "    numProdBig = len(bigList[1])\n",
    "    intersectionTgtBig = set.intersection(*bigList)\n",
    "\n",
    "    return len( intersectionTgtBig ) / numProdBig\n",
    "\n",
    "# test\n",
    "#b1 = getBigrams(\"this is a sample sentence\")\n",
    "#b2 = getBigrams(\"this is a very cool sample sentence\")\n",
    "#print( searchForBigrams( b1,b2))  # works out all right!\n",
    "    \n",
    "def bigramDriver(dataframe_row):\n",
    "    b1 = getBigrams(dataframe_row['Produced Sentence'])\n",
    "    b2 = getBigrams(dataframe_row['Target Sentence'])\n",
    "    \n",
    "    proportion = searchForBigrams(b1,b2)\n",
    "    return proportion\n",
    "\n",
    "'''trials['proportionMatchingBigram'] = trials.apply(bigramDriver, axis=1)\n",
    "\n",
    "print(trials[:5])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# edit distance between production and original\n",
    "# https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance#Python\n",
    "\n",
    "# this might actually need to be optimized\n",
    "def levenshtein(s, t):\n",
    "        ''' From Wikipedia article; Iterative with two matrix rows. '''\n",
    "        if s == t: return 0\n",
    "        elif len(s) == 0: return len(t)\n",
    "        elif len(t) == 0: return len(s)\n",
    "        v0 = [None] * (len(t) + 1)\n",
    "        v1 = [None] * (len(t) + 1)\n",
    "        for i in range(len(v0)):\n",
    "            v0[i] = i\n",
    "        for i in range(len(s)):\n",
    "            v1[0] = i + 1\n",
    "            for j in range(len(t)):\n",
    "                cost = 0 if s[i] == t[j] else 1\n",
    "                v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)\n",
    "            for j in range(len(v0)):\n",
    "                v0[j] = v1[j]\n",
    "                \n",
    "        return v1[len(t)]\n",
    "\n",
    "    \n",
    "def editDriver( dataframe_row ):\n",
    "    a = dataframe_row['Produced Sentence']\n",
    "    b = dataframe_row['Target Sentence']\n",
    "    \n",
    "    return levenshtein( a, b )\n",
    "\n",
    "'''s = \"the equipment was often moved quickly when inspectors were about to arrive\"\n",
    "t = \"equipment was often quickly moved when the inspectors were about to arrive\"\n",
    "print(levenshtein(s,t))'''\n",
    "\n",
    "trials['editDist'] = trials.apply(editDriver, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def longest_common_substring(s1, s2):\n",
    "    '''\n",
    "    https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Longest_common_substring#Python_3\n",
    "    '''\n",
    "    m = [[0] * (1 + len(s2)) for i in range(1 + len(s1))]\n",
    "    longest, x_longest = 0, 0\n",
    "    for x in range(1, 1 + len(s1)):\n",
    "        for y in range(1, 1 + len(s2)):\n",
    "            if s1[x - 1] == s2[y - 1]:\n",
    "                m[x][y] = m[x - 1][y - 1] + 1\n",
    "                if m[x][y] > longest:\n",
    "                    longest = m[x][y]\n",
    "                    x_longest = x\n",
    "            else:\n",
    "                m[x][y] = 0\n",
    "    return s1[x_longest - longest: x_longest]\n",
    "\n",
    "\n",
    "def lcsDriver( dataframe_row ):\n",
    "    b1 = dataframe_row['Produced Sentence']\n",
    "    b2 = dataframe_row['Target Sentence']\n",
    "    \n",
    "    lcs = longest_common_substring(b1,b2)\n",
    "    return lcs\n",
    "\n",
    "s = \"The dog jumped merrily over the languishing cat.\"\n",
    "t = \"The zebra soared merrily over the languishing cat.\"\n",
    "\n",
    "#print(longest_common_substring(s,t))   # ed merrily over the languishing cat.\n",
    "\n",
    "trials['lcs'] = trials.apply(lcsDriver, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         MTurk ID  Sentence Number  List Number  Subset Number  Trial Number  \\\n",
      "1  A30RAYNDOWQ61S               56            3              2             2   \n",
      "2  A30RAYNDOWQ61S               51            3              2             3   \n",
      "3  A30RAYNDOWQ61S               91            3              2             4   \n",
      "4  A30RAYNDOWQ61S               58            3              2             5   \n",
      "5  A30RAYNDOWQ61S               83            3              2             6   \n",
      "\n",
      "                                     Target Sentence  \\\n",
      "1  the blast shattered the windows of the villa a...   \n",
      "2  the equipment was often moved quickly when ins...   \n",
      "3  evidence from abroad showed students were prep...   \n",
      "4  south africa has openly expressed willingness ...   \n",
      "5  the regular bus service had been suspended bec...   \n",
      "\n",
      "                                  Scrambled Sentence  \\\n",
      "1  neighbouring windows shattered the other the h...   \n",
      "2  the to quickly equipment inspectors moved were...   \n",
      "3  showed students large to were out loans eviden...   \n",
      "4  with openly africa establish china to has sout...   \n",
      "5  been suspended bus because fuel the the servic...   \n",
      "\n",
      "                                   Produced Sentence  Time (ms)          Time  \\\n",
      "1  the blast shattered the windows of the villa a...     117637  1 min 57 sec   \n",
      "2  equipment was often quickly moved when the ins...     513810  8 min 33 sec   \n",
      "3  evidence showed students from abroad were prep...      78273  1 min 18 sec   \n",
      "4  south africa has expressed willingness to open...      85852  1 min 25 sec   \n",
      "5  the regular bus service had been suspended bec...      75546  1 min 15 sec   \n",
      "\n",
      "  Bugged ProdMatchesOrig  proportionMatchingBigram  editDist  \\\n",
      "1   Safe            True                  1.000000         0   \n",
      "2   Safe           False                  0.545455        20   \n",
      "3   Safe           False                  0.727273        24   \n",
      "4   Safe           False                  0.727273        14   \n",
      "5   Safe            True                  1.000000         0   \n",
      "\n",
      "                                                 lcs  \n",
      "1  the blast shattered the windows of the villa a...  \n",
      "2                    inspectors were about to arrive  \n",
      "3              were prepared to take out large loans  \n",
      "4               establish diplomatic ties with china  \n",
      "5  the regular bus service had been suspended bec...  \n"
     ]
    }
   ],
   "source": [
    "print(trials[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/clips/pattern/blob/master/pattern/vector/stopwords-en.txt\n",
    "stop = set(''''d, 'll, 'm, 're, 's, 't, n't, 've, a, aboard, about, above, across, after, again, against, all, almost, alone, along, alongside, already, also, although, always, am, amid, amidst, among, amongst, an, and, another, anti, any, anybody, anyone, anything, anywhere, are, area, areas, aren't, around, as, ask, asked, asking, asks, astride, at, aught, away, back, backed, backing, backs, bar, barring, be, became, because, become, becomes, been, before, began, behind, being, beings, below, beneath, beside, besides, best, better, between, beyond, big, both, but, by, came, can, can't, cannot, case, cases, certain, certainly, circa, clear, clearly, come, concerning, considering, could, couldn't, daren't, despite, did, didn't, differ, different, differently, do, does, doesn't, doing, don't, done, down, down, downed, downing, downs, during, each, early, either, end, ended, ending, ends, enough, even, evenly, ever, every, everybody, everyone, everything, everywhere, except, excepting, excluding, face, faces, fact, facts, far, felt, few, fewer, find, finds, first, five, following, for, four, from, full, fully, further, furthered, furthering, furthers, gave, general, generally, get, gets, give, given, gives, go, goes, going, good, goods, got, great, greater, greatest, group, grouped, grouping, groups, had, hadn't, has, hasn't, have, haven't, having, he, he'd, he'll, he's, her, here, here's, hers, herself, high, high, high, higher, highest, him, himself, his, hisself, how, how's, however, i, i'd, i'll, i'm, i've, idem, if, ilk, important, in, including, inside, interest, interested, interesting, interests, into, is, isn't, it, it's, its, itself, just, keep, keeps, kind, knew, know, known, knows, large, largely, last, later, latest, least, less, let, let's, lets, like, likely, long, longer, longest, made, make, making, man, many, may, me, member, members, men, might, mightn't, mine, minus, more, most, mostly, mr, mrs, much, must, mustn't, my, myself, naught, near, necessary, need, needed, needing, needn't, needs, neither, never, new, new, newer, newest, next, no, nobody, non, none, noone, nor, not, nothing, notwithstanding, now, nowhere, number, numbers, of, off, often, old, older, oldest, on, once, one, oneself, only, onto, open, opened, opening, opens, opposite, or, order, ordered, ordering, orders, other, others, otherwise, ought, oughtn't, our, ours, ourself, ourselves, out, outside, over, own, part, parted, parting, parts, past, pending, per, perhaps, place, places, plus, point, pointed, pointing, points, possible, present, presented, presenting, presents, problem, problems, put, puts, quite, rather, really, regarding, right, right, room, rooms, round, said, same, save, saw, say, says, second, seconds, see, seem, seemed, seeming, seems, seen, sees, self, several, shall, shan't, she, she'd, she'll, she's, should, shouldn't, show, showed, showing, shows, side, sides, since, small, smaller, smallest, so, some, somebody, someone, something, somewhat, somewhere, state, states, still, still, such, suchlike, sundry, sure, take, taken, than, that, that's, the, thee, their, theirs, them, themselves, then, there, there's, therefore, these, they, they'd, they'll, they're, they've, thine, thing, things, think, thinks, this, those, thou, though, thought, thoughts, three, through, throughout, thus, thyself, till, to, today, together, too, took, tother, toward, towards, turn, turned, turning, turns, twain, two, under, underneath, unless, unlike, until, up, upon, us, use, used, uses, various, versus, very, via, vis-a-vis, want, wanted, wanting, wants, was, wasn't, way, ways, we, we'd, we'll, we're, we've, well, wells, went, were, weren't, what, what's, whatall, whatever, whatsoever, when, when's, where, where's, whereas, wherewith, wherewithal, whether, which, whichever, whichsoever, while, who, who's, whoever, whole, whom, whomever, whomso, whomsoever, whose, whosoever, why, why's, will, with, within, without, won't, work, worked, working, works, worth, would, wouldn't, ye, year, years, yet, yon, yonder, you, you'd, you'll, you're, you've, you-all, young, younger, youngest, your, yours, yourself, yourselves'''.split(', '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removeStopWords( s ):\n",
    "    production = s.split( )\n",
    "    for i in production:\n",
    "        if i in stop:\n",
    "            s = re.sub(r\"\\s{0}\\s\".format(i),' ',s)\n",
    "    return s.split( )\n",
    "            \n",
    "def deltaDistanceDriver(dataframe_row):    \n",
    "    prod_content = dataframe_row['Produced Sentence']\n",
    "    target_content = dataframe_row[\"Target Sentence\"]\n",
    "    \n",
    "    prod_content = ' '.join(removeStopWords(prod_content))\n",
    "    target_content = ' '.join(removeStopWords(target_content))\n",
    "\n",
    "    bigrams = getBigrams(target_content)\n",
    "    \n",
    "    all_matches = []\n",
    "    for bigram in bigrams:\n",
    "        match = re.findall(r\"{0}\\s(.*)\\s{1}\".format(bigram[0], bigram[1]), prod_content)\n",
    "        if match:\n",
    "            matches = match[0].split()\n",
    "            all_matches += matches\n",
    "            \n",
    "    ratio = len(all_matches) / len(bigrams)\n",
    "    return ratio\n",
    "            \n",
    "#trials['deltaDistance'] = trials.apply(deltaDistanceDriver, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        MTurk ID  Sentence Number  List Number  Subset Number  \\\n",
      "0           1  A30RAYNDOWQ61S               56            3              2   \n",
      "1           2  A30RAYNDOWQ61S               51            3              2   \n",
      "2           3  A30RAYNDOWQ61S               91            3              2   \n",
      "3           4  A30RAYNDOWQ61S               58            3              2   \n",
      "4           5  A30RAYNDOWQ61S               83            3              2   \n",
      "\n",
      "   Trial Number                                    Target Sentence  \\\n",
      "0             2  the blast shattered the windows of the villa a...   \n",
      "1             3  the equipment was often moved quickly when ins...   \n",
      "2             4  evidence from abroad showed students were prep...   \n",
      "3             5  south africa has openly expressed willingness ...   \n",
      "4             6  the regular bus service had been suspended bec...   \n",
      "\n",
      "                                  Scrambled Sentence  \\\n",
      "0  neighbouring windows shattered the other the h...   \n",
      "1  the to quickly equipment inspectors moved were...   \n",
      "2  showed students large to were out loans eviden...   \n",
      "3  with openly africa establish china to has sout...   \n",
      "4  been suspended bus because fuel the the servic...   \n",
      "\n",
      "                                   Produced Sentence  Time (ms)          Time  \\\n",
      "0  the blast shattered the windows of the villa a...     117637  1 min 57 sec   \n",
      "1  equipment was often quickly moved when the ins...     513810  8 min 33 sec   \n",
      "2  evidence showed students from abroad were prep...      78273  1 min 18 sec   \n",
      "3  south africa has expressed willingness to open...      85852  1 min 25 sec   \n",
      "4  the regular bus service had been suspended bec...      75546  1 min 15 sec   \n",
      "\n",
      "  Bugged ProdMatchesOrig  proportionMatchingBigram  editDist  \\\n",
      "0   Safe            True                  1.000000         0   \n",
      "1   Safe           False                  0.545455        20   \n",
      "2   Safe           False                  0.727273        24   \n",
      "3   Safe           False                  0.727273        14   \n",
      "4   Safe            True                  1.000000         0   \n",
      "\n",
      "                                                 lcs  \\\n",
      "0  the blast shattered the windows of the villa a...   \n",
      "1                    inspectors were about to arrive   \n",
      "2              were prepared to take out large loans   \n",
      "3               establish diplomatic ties with china   \n",
      "4  the regular bus service had been suspended bec...   \n",
      "\n",
      "                                       deltaDistance  deltaDistance2  \n",
      "0                                                 []           0.000  \n",
      "1             [(['quickly'], 0.2), (['moved'], 0.2)]           0.400  \n",
      "2         [(['students'], 0.25), (['abroad'], 0.25)]           0.500  \n",
      "3  [(['expressed willingness'], 0.25), (['openly'...           0.375  \n",
      "4                                                 []           0.000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aik/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/analyzed_data.tsv\", sep=\"\\t\")\n",
    "\n",
    "test = data[:10]\n",
    "test['deltaDistance2'] = test.apply(deltaDistanceDriver, axis=1)\n",
    "print(test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials.to_csv(\"../data/analyzed_data.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['the windows of'], 0.2727272727272727)\n",
      "(['blast shattered the'], 0.2727272727272727)\n",
      "(['blast shattered the windows of the'], 0.5454545454545454)\n"
     ]
    }
   ],
   "source": [
    "a = trials[trials['Trial Number']==2]\n",
    "s = a.iloc[0]['Target Sentence']\n",
    "t = a.iloc[0]['Produced Sentence']\n",
    "\n",
    "target_content = ' '.join(removeStopWords(s))\n",
    "bigrams = getBigrams(s)\n",
    "\n",
    "matches_ratios = []\n",
    "for bigram in bigrams:\n",
    "    match = re.findall(r\"{0}\\s(.*)\\s{1}\".format(bigram[0], bigram[1]), t)\n",
    "    if match:\n",
    "        matches = match[0].split()\n",
    "        ratio = len(matches) / len(bigrams)\n",
    "        matches_ratios.append((match,ratio))\n",
    "\n",
    "for i in matches_ratios:\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "test = trials[:10]\n",
    "test['deltaDistance'] = test.apply(deltaDistanceDriver, axis=1)\n",
    "print(test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
